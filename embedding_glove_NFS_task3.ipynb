{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "embedding_glove_NFS_task3.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "pKj4UeahQPad",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "a7ac5875-08d7-4315-9d74-625f66e2f565",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529479225383,
          "user_tz": -600,
          "elapsed": 22910,
          "user": {
            "displayName": "Ming Xie",
            "photoUrl": "//lh3.googleusercontent.com/-uIPBPBSor2U/AAAAAAAAAAI/AAAAAAAAAH8/xhLECXv6LFA/s50-c-k-no/photo.jpg",
            "userId": "100284084012565045167"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# requirements for this task to run\n",
        "# Pandas\n",
        "# Gensim\n",
        "# Sklearn\n",
        "\n",
        "import io, os, sys, types, time, datetime, math, random, requests, subprocess, tempfile\n",
        "import gensim.models.keyedvectors\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "# -----------------------\n",
        "# set up task options\n",
        "#------------------------\n",
        "\n",
        "MAX_NUM_WORDS = 10000\n",
        "EMB_DIMS = 50\n",
        "\n",
        "sen1 = \"how are you\"\n",
        "sen2 = \"nice to meet you and good day\"\n",
        "\n",
        "# ----------------------\n",
        "# helper functions\n",
        "# ----------------------\n",
        "\n",
        "def sentence_avg(sentence):\n",
        "  # A list to aggreate\n",
        "  sum = []\n",
        "  keylist = list(word_index.keys())\n",
        "  for word in sentence:\n",
        "    word = keylist[word-1]\n",
        "    if word in w2v_gl:\n",
        "      sum.append(w2v_gl[word])\n",
        "  sum = np.array(sum)\n",
        "  return sum.mean(0)\n",
        "\n",
        "# Note when call fit_on_texts, it must be entire corpus, not a sentence\n",
        "tokenizer = keras.preprocessing.text.Tokenizer(num_words = MAX_NUM_WORDS)\n",
        "corpus = (sen1, sen2)\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "X = tokenizer.texts_to_sequences(corpus)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "PRE_TRAINED_EMBEDDING = '50d.w2vformat.txt'\n",
        "model_g = gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(PRE_TRAINED_EMBEDDING, binary = False)\n",
        "w2v_gl = {w: vec for w, vec in zip((model_g.vocab), model_g.vectors)}\n",
        "print(w2v_gl['word'])\n",
        "print(X)\n",
        "\n",
        "print(sentence_avg(X[0], EMB_DIMS))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.1643     0.15722   -0.55021   -0.3303     0.66463   -0.1152\n",
            " -0.2261    -0.23674   -0.86119    0.24319    0.074499   0.61081\n",
            "  0.73683   -0.35224    0.61346    0.0050975 -0.62538   -0.0050458\n",
            "  0.18392   -0.12214   -0.65973   -0.30673    0.35038    0.75805\n",
            "  1.0183    -1.7424    -1.4277     0.38032    0.37713   -0.74941\n",
            "  2.9401    -0.8097    -0.66901    0.23123   -0.073194  -0.13624\n",
            "  0.24424   -1.0129    -0.24919   -0.06893    0.70231   -0.022177\n",
            " -0.64684    0.59599    0.027092   0.11203    0.61214    0.74339\n",
            "  0.23572   -0.1369   ]\n",
            "[[2, 3, 1], [4, 5, 6, 1, 7, 8, 9]]\n",
            "[ 5.50072670e-01  7.97720030e-02  2.48529986e-01 -3.27209979e-01\n",
            "  6.13483310e-01 -5.24228401e-02 -4.36006635e-01 -2.67500937e-01\n",
            " -2.83643335e-01  9.96333361e-02 -2.75326997e-01  6.30840003e-01\n",
            " -1.77470013e-01  1.13804005e-01  8.46876621e-01  6.11603320e-01\n",
            "  5.24820030e-01  7.79526606e-02  3.33656669e-01 -1.14258659e+00\n",
            " -3.31656665e-01  2.83790022e-01  8.38809967e-01  4.56220031e-01\n",
            "  6.09003305e-01 -1.72724664e+00 -9.89873350e-01  1.50618866e-01\n",
            "  7.69889355e-01 -1.07127333e+00  3.82106662e+00  6.01750016e-01\n",
            " -2.74553329e-01 -5.69046676e-01 -4.50015068e-04  2.64713336e-02\n",
            " -1.02426670e-01  1.37043074e-01  1.19283348e-01 -2.67743349e-01\n",
            " -3.02739978e-01  6.50120005e-02  3.03463310e-01  8.50030005e-01\n",
            "  3.36406678e-01  1.82123318e-01 -6.09399974e-02  3.36533301e-02\n",
            " -2.19563007e-01  4.52866673e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bJ2US_QtZ5ps",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load Raw csv\n",
        "Here we try to import the data and load it into a Pandas data frame object"
      ]
    },
    {
      "metadata": {
        "id": "PIFnKRVWgbSC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dc8ffe98-7955-4f9f-9c40-d4560131621f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529470377064,
          "user_tz": -600,
          "elapsed": 1754,
          "user": {
            "displayName": "Ming Xie",
            "photoUrl": "//lh3.googleusercontent.com/-uIPBPBSor2U/AAAAAAAAAAI/AAAAAAAAAH8/xhLECXv6LFA/s50-c-k-no/photo.jpg",
            "userId": "100284084012565045167"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datafiles  glove.6B.100d.txt  glove.6B.300d.txt  glove.6B.zip\r\n",
            "datalab    glove.6B.200d.txt  glove.6B.50d.txt\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N9NWX0EyR64A",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DGGvnwwlSJCE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CoMMEJv_gjq1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "835c4948-040d-473a-f494-658e22a5afbf",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529470447337,
          "user_tz": -600,
          "elapsed": 21198,
          "user": {
            "displayName": "Ming Xie",
            "photoUrl": "//lh3.googleusercontent.com/-uIPBPBSor2U/AAAAAAAAAAI/AAAAAAAAAH8/xhLECXv6LFA/s50-c-k-no/photo.jpg",
            "userId": "100284084012565045167"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# This steps required only if the file has not been in word2vec format\n",
        "!pip install -q gensim\n",
        "!python -m gensim.scripts.glove2word2vec --input glove.6B.50d.txt --output 50d.w2vformat.txt"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'gensim.scripts.glove2word2vec' found in sys.modules after import of package 'gensim.scripts', but prior to execution of 'gensim.scripts.glove2word2vec'; this may result in unpredictable behaviour\r\n",
            "  warn(RuntimeWarning(msg))\r\n",
            "2018-06-20 04:54:00,737 - glove2word2vec - INFO - running /usr/local/lib/python3.6/dist-packages/gensim/scripts/glove2word2vec.py --input glove.6B.50d.txt --output 50d.w2vformat.txt\n",
            "2018-06-20 04:54:08,250 - glove2word2vec - INFO - converting 400000 vectors from glove.6B.50d.txt to 50d.w2vformat.txt\n",
            "2018-06-20 04:54:09,097 - glove2word2vec - INFO - Converted model with 400000 vectors and 50 dimensions\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CGeNmUC7i5KU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "5b506391-1d09-48a9-a413-dcc3643ce37c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529471623021,
          "user_tz": -600,
          "elapsed": 22829,
          "user": {
            "displayName": "Ming Xie",
            "photoUrl": "//lh3.googleusercontent.com/-uIPBPBSor2U/AAAAAAAAAAI/AAAAAAAAAH8/xhLECXv6LFA/s50-c-k-no/photo.jpg",
            "userId": "100284084012565045167"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# embedding file for glove.6B.50D, replace with your file\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "PRE_TRAINED_EMBEDDING = '50d.w2vformat.txt'\n",
        "model_g = gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(PRE_TRAINED_EMBEDDING, binary = False)\n",
        "w2v_gl = {w: vec for w, vec in zip((model_g.vocab), model_g.vectors)}\n",
        "print(w2v_gl['word'])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.1643     0.15722   -0.55021   -0.3303     0.66463   -0.1152\n",
            " -0.2261    -0.23674   -0.86119    0.24319    0.074499   0.61081\n",
            "  0.73683   -0.35224    0.61346    0.0050975 -0.62538   -0.0050458\n",
            "  0.18392   -0.12214   -0.65973   -0.30673    0.35038    0.75805\n",
            "  1.0183    -1.7424    -1.4277     0.38032    0.37713   -0.74941\n",
            "  2.9401    -0.8097    -0.66901    0.23123   -0.073194  -0.13624\n",
            "  0.24424   -1.0129    -0.24919   -0.06893    0.70231   -0.022177\n",
            " -0.64684    0.59599    0.027092   0.11203    0.61214    0.74339\n",
            "  0.23572   -0.1369   ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3WLvEB4pOZyX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Psesudo code only, don't work \n",
        "DATASET = (\n",
        "  \"http://any.com/my/data.file1\",\n",
        "  \"http://any.com/my/data.file2\",\n",
        ")\n",
        "\n",
        "#Download the embedding vectors from glove\n",
        "def download_data(path='datafiles', urls=DATASET):\n",
        "    if not os.path.exists(path):\n",
        "        os.mkdir(path)\n",
        "        \n",
        "    for url in urls:\n",
        "        response = requests.get(url)\n",
        "        name = os.path.basename(url)\n",
        "        with open(os.path.join(path, name), 'w') as f:\n",
        "            f.write(response.content.decode('utf-8'))\n",
        "\n",
        "            \n",
        "download_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nJpNjXvkhdwf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def download_glove():\n",
        "  em_file = 'glove.6B.zip'\n",
        "  tf.keras.utils.get_file(\n",
        "      fname=em_file,\n",
        "      \n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}