{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "embedding_glove_NFS_task3.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "2AMtUBtG00uE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Task Overview\n",
        "===="
      ]
    },
    {
      "metadata": {
        "id": "IjUM7pjBvn-N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Brief\n",
        "TASK 3: RISK STRATIFICATION FOR ‘ACTUAL HARM” BASED ON\n",
        "‘EVENT DESCRIPTION’\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ZLyGpf-j1BUY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Requirements\n",
        "\n",
        "To assist the Department to utilise text mining and machine learning techniques\n",
        "for risk stratification of events and examine the link between the ‘Event\n",
        "Description’ and ‘Actual Harm’."
      ]
    },
    {
      "metadata": {
        "id": "Cgq6RwS70ndQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Machine Learning Step 1\n",
        "==="
      ]
    },
    {
      "metadata": {
        "id": "h4yFaAsD1Z0v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this step we are going to extract a dataset"
      ]
    },
    {
      "metadata": {
        "id": "Mj73FYp51tXH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8112792f-3b30-4288-b958-45996b17e4f7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529542605494,
          "user_tz": -600,
          "elapsed": 2007,
          "user": {
            "displayName": "Ming Xie",
            "photoUrl": "//lh3.googleusercontent.com/-uIPBPBSor2U/AAAAAAAAAAI/AAAAAAAAAH8/xhLECXv6LFA/s50-c-k-no/photo.jpg",
            "userId": "100284084012565045167"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# We need a Python verison 3.x to run following program\n",
        "# To show python version, do the following\n",
        "!python -V"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.3\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eYWsP_zoHTTG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can move to download, extracting the pre-trained embedding"
      ]
    },
    {
      "metadata": {
        "id": "ntENUmBhGJ4E",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip\n",
        "# This steps required only if the file has not been in word2vec format\n",
        "!pip install -q gensim\n",
        "!python -m gensim.scripts.glove2word2vec --input glove.6B.50d.txt --output 50d.w2vformat.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pKj4UeahQPad",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# requirements for this task to run\n",
        "# Pandas\n",
        "# Gensim\n",
        "# Sklearn\n",
        "\n",
        "import io, os, sys, types, time, datetime, math, random, requests, subprocess, tempfile\n",
        "import gensim.models.keyedvectors\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "# -----------------------\n",
        "# set up task options\n",
        "#------------------------\n",
        "\n",
        "MAX_NUM_WORDS = 10000\n",
        "EMB_DIMS = 50\n",
        "\n",
        "sen1 = \"how are you\"\n",
        "sen2 = \"nice to meet you and good day\"\n",
        "\n",
        "# ----------------------\n",
        "# helper functions\n",
        "# ----------------------\n",
        "\n",
        "def sentence_avg(sentence):\n",
        "  # A list to aggreate\n",
        "  sum = []\n",
        "  keylist = list(word_index.keys())\n",
        "  for word in sentence:\n",
        "    # Note, I have idea to add an word 'UNK' to keys, so we don't need \n",
        "    # the -1 offset to get the word reversely\n",
        "    word = keylist[word-1]\n",
        "    if word in w2v_gl:\n",
        "      sum.append(w2v_gl[word])\n",
        "  sum = np.array(sum)\n",
        "  return sum.mean(0)\n",
        "\n",
        "# Note when call fit_on_texts, it must be entire corpus, not a sentence\n",
        "tokenizer = keras.preprocessing.text.Tokenizer(num_words = MAX_NUM_WORDS)\n",
        "corpus = (sen1, sen2)\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "X = tokenizer.texts_to_sequences(corpus)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "\n",
        "PRE_TRAINED_EMBEDDING = '50d.w2vformat.txt'\n",
        "model_g = gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(PRE_TRAINED_EMBEDDING, binary = False)\n",
        "w2v_gl = {w: vec for w, vec in zip((model_g.vocab), model_g.vectors)}\n",
        "print(w2v_gl['word'])\n",
        "print(X)\n",
        "\n",
        "y = [[1], [0]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bJ2US_QtZ5ps",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Machine Learning Step 2\n",
        "==="
      ]
    },
    {
      "metadata": {
        "id": "PIFnKRVWgbSC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dc8ffe98-7955-4f9f-9c40-d4560131621f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529470377064,
          "user_tz": -600,
          "elapsed": 1754,
          "user": {
            "displayName": "Ming Xie",
            "photoUrl": "//lh3.googleusercontent.com/-uIPBPBSor2U/AAAAAAAAAAI/AAAAAAAAAH8/xhLECXv6LFA/s50-c-k-no/photo.jpg",
            "userId": "100284084012565045167"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datafiles  glove.6B.100d.txt  glove.6B.300d.txt  glove.6B.zip\r\n",
            "datalab    glove.6B.200d.txt  glove.6B.50d.txt\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CGeNmUC7i5KU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "5b506391-1d09-48a9-a413-dcc3643ce37c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529471623021,
          "user_tz": -600,
          "elapsed": 22829,
          "user": {
            "displayName": "Ming Xie",
            "photoUrl": "//lh3.googleusercontent.com/-uIPBPBSor2U/AAAAAAAAAAI/AAAAAAAAAH8/xhLECXv6LFA/s50-c-k-no/photo.jpg",
            "userId": "100284084012565045167"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# embedding file for glove.6B.50D, replace with your file\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "PRE_TRAINED_EMBEDDING = '50d.w2vformat.txt'\n",
        "model_g = gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(PRE_TRAINED_EMBEDDING, binary = False)\n",
        "w2v_gl = {w: vec for w, vec in zip((model_g.vocab), model_g.vectors)}\n",
        "print(w2v_gl['word'])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.1643     0.15722   -0.55021   -0.3303     0.66463   -0.1152\n",
            " -0.2261    -0.23674   -0.86119    0.24319    0.074499   0.61081\n",
            "  0.73683   -0.35224    0.61346    0.0050975 -0.62538   -0.0050458\n",
            "  0.18392   -0.12214   -0.65973   -0.30673    0.35038    0.75805\n",
            "  1.0183    -1.7424    -1.4277     0.38032    0.37713   -0.74941\n",
            "  2.9401    -0.8097    -0.66901    0.23123   -0.073194  -0.13624\n",
            "  0.24424   -1.0129    -0.24919   -0.06893    0.70231   -0.022177\n",
            " -0.64684    0.59599    0.027092   0.11203    0.61214    0.74339\n",
            "  0.23572   -0.1369   ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QYTn7MtwHoVR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Machine Learning Step 3\n",
        "==="
      ]
    },
    {
      "metadata": {
        "id": "4rQIe5EOH2xP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# define classifier"
      ]
    },
    {
      "metadata": {
        "id": "CWyI5619HxKR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "\n",
        "# you need to divide training and test set before this step\n",
        "\n",
        "# Here the logit classifier just use default hyperparameter\n",
        "\n",
        "C = 1.0\n",
        "\n",
        "classifier = sklearn.linear_model.LogisticRegression(C=C)\n",
        "\n",
        "classifier.fit(X, y)\n",
        "\n",
        "y_pred = classifier.predict(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_HO1yiutM2YL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "assume we use tfidf as the vectorizer"
      ]
    },
    {
      "metadata": {
        "id": "5QTP_uEUMxnT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "3e4cb451-56b6-4595-a7f7-207d5456adb3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529565625584,
          "user_tz": -600,
          "elapsed": 889,
          "user": {
            "displayName": "Ming Xie",
            "photoUrl": "//lh3.googleusercontent.com/-uIPBPBSor2U/AAAAAAAAAAI/AAAAAAAAAH8/xhLECXv6LFA/s50-c-k-no/photo.jpg",
            "userId": "100284084012565045167"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#in Scikit-Learn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tokenize = lambda doc: doc.lower().split(\" \")\n",
        "\n",
        "document_0 = \"China has a strong economy that is growing at a rapid pace. However politically it differs greatly from the US Economy.\"\n",
        "document_1 = \"At last, China seems serious about confronting an endemic problem: domestic violence and corruption.\"\n",
        "document_2 = \"Japan's prime minister, Shinzo Abe, is working towards healing the economic turmoil in his own country for his view on the future of his people.\"\n",
        "document_3 = \"Vladimir Putin is working hard to fix the economy in Russia as the Ruble has tumbled.\"\n",
        "document_4 = \"What's the future of Abenomics? We asked Shinzo Abe for his views\"\n",
        "document_5 = \"Obama has eased sanctions on Cuba while accelerating those against the Russian Economy, even as the Ruble's value falls almost daily.\"\n",
        "document_6 = \"Vladimir Putin was found to be riding a horse, again, without a shirt on while hunting deer. Vladimir Putin always seems so serious about things - even riding horses.\"\n",
        "\n",
        "all_documents = [document_0, document_1, document_2, document_3, document_4, document_5, document_6]\n",
        "\n",
        "sklearn_tfidf = TfidfVectorizer(norm='l2',min_df=0, use_idf=True, smooth_idf=False, sublinear_tf=True, tokenizer=tokenize)\n",
        "sklearn_representation = sklearn_tfidf.fit_transform(all_documents)\n",
        "\n",
        "print(sklearn_representation)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 17)\t0.18320378146489946\n",
            "  (0, 42)\t0.15022972156764192\n",
            "  (0, 1)\t0.31019096605521496\n",
            "  (0, 77)\t0.23957330918096045\n",
            "  (0, 28)\t0.18320378146489946\n",
            "  (0, 78)\t0.23957330918096045\n",
            "  (0, 50)\t0.15022972156764192\n",
            "  (0, 40)\t0.23957330918096045\n",
            "  (0, 15)\t0.18320378146489946\n",
            "  (0, 65)\t0.23957330918096045\n",
            "  (0, 59)\t0.23957330918096045\n",
            "  (0, 47)\t0.23957330918096045\n",
            "  (0, 61)\t0.23957330918096045\n",
            "  (0, 51)\t0.23957330918096045\n",
            "  (0, 24)\t0.23957330918096045\n",
            "  (0, 39)\t0.23957330918096045\n",
            "  (0, 37)\t0.23957330918096045\n",
            "  (0, 79)\t0.10868731908150663\n",
            "  (0, 86)\t0.23957330918096045\n",
            "  (0, 30)\t0.23957330918096045\n",
            "  (1, 17)\t0.2214557196249166\n",
            "  (1, 15)\t0.2214557196249166\n",
            "  (1, 53)\t0.2895948935298433\n",
            "  (1, 72)\t0.2214557196249166\n",
            "  (1, 73)\t0.2214557196249166\n",
            "  :\t:\n",
            "  (6, 1)\t0.2549169133624212\n",
            "  (6, 72)\t0.1505580355265494\n",
            "  (6, 73)\t0.1505580355265494\n",
            "  (6, 5)\t0.1505580355265494\n",
            "  (6, 57)\t0.12345974289432536\n",
            "  (6, 91)\t0.2549169133624212\n",
            "  (6, 64)\t0.2549169133624212\n",
            "  (6, 82)\t0.1505580355265494\n",
            "  (6, 95)\t0.1505580355265494\n",
            "  (6, 32)\t0.1505580355265494\n",
            "  (6, 92)\t0.19688287275768235\n",
            "  (6, 36)\t0.19688287275768235\n",
            "  (6, 16)\t0.19688287275768235\n",
            "  (6, 66)\t0.3333516809102124\n",
            "  (6, 45)\t0.19688287275768235\n",
            "  (6, 7)\t0.19688287275768235\n",
            "  (6, 96)\t0.19688287275768235\n",
            "  (6, 75)\t0.19688287275768235\n",
            "  (6, 48)\t0.19688287275768235\n",
            "  (6, 23)\t0.19688287275768235\n",
            "  (6, 10)\t0.19688287275768235\n",
            "  (6, 76)\t0.19688287275768235\n",
            "  (6, 80)\t0.19688287275768235\n",
            "  (6, 0)\t0.19688287275768235\n",
            "  (6, 46)\t0.19688287275768235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fGi0j9J2OqkL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "f18fe839-bc76-4f56-97a0-8d5da96b3550",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529565910896,
          "user_tz": -600,
          "elapsed": 689,
          "user": {
            "displayName": "Ming Xie",
            "photoUrl": "//lh3.googleusercontent.com/-uIPBPBSor2U/AAAAAAAAAAI/AAAAAAAAAH8/xhLECXv6LFA/s50-c-k-no/photo.jpg",
            "userId": "100284084012565045167"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "type(sklearn_representation)\n",
        "df_list = iter(sklearn_representation)\n",
        "a = next(df_list)\n",
        "print(a)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 17)\t0.18320378146489946\n",
            "  (0, 42)\t0.15022972156764192\n",
            "  (0, 1)\t0.31019096605521496\n",
            "  (0, 77)\t0.23957330918096045\n",
            "  (0, 28)\t0.18320378146489946\n",
            "  (0, 78)\t0.23957330918096045\n",
            "  (0, 50)\t0.15022972156764192\n",
            "  (0, 40)\t0.23957330918096045\n",
            "  (0, 15)\t0.18320378146489946\n",
            "  (0, 65)\t0.23957330918096045\n",
            "  (0, 59)\t0.23957330918096045\n",
            "  (0, 47)\t0.23957330918096045\n",
            "  (0, 61)\t0.23957330918096045\n",
            "  (0, 51)\t0.23957330918096045\n",
            "  (0, 24)\t0.23957330918096045\n",
            "  (0, 39)\t0.23957330918096045\n",
            "  (0, 37)\t0.23957330918096045\n",
            "  (0, 79)\t0.10868731908150663\n",
            "  (0, 86)\t0.23957330918096045\n",
            "  (0, 30)\t0.23957330918096045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qQw7JiEjOtuu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}